{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Harry Chong\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import tensorflow_datasets as tfds\n",
    "import tensorflow_hub as hub\n",
    "import tensorflow_addons as tfa\n",
    "import seaborn as sn\n",
    "import random\n",
    "from tensorflow import keras\n",
    "from preprocessDefinition import preprocess\n",
    "from tensorflow.keras.layers import Input, LSTM, Embedding, Dense, Concatenate, TimeDistributed\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer \n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.python.keras.layers import Layer\n",
    "from tensorflow.python.keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# README: I could not load the most recent dataset (20200301.en) with tensorflow-dataset version 4.1.0 as I kept getting an error message\n",
    "# regarding Apache Beam and how the dataset is too large. In order for me to get around this issue, I had to downgrade my tensorflow_datasets \n",
    "# package to version 2.0.0. Doing so allowed me to load the dataset into jupyter notebook.\n",
    "dataset, info = tfds.load(\"wikipedia/20190301.en\", split='train' ,with_info=True)\n",
    "#dataset_size = info.splits[\"train\"].num_examples # Total size = 5,824,596\n",
    "\n",
    "train_set = dataset.take(100000)\n",
    "\n",
    "# Preprocess article content and title\n",
    "raw_x_train = [] # Article Content \n",
    "raw_y_train = [] # Article Title\n",
    "\n",
    "for x in train_set.batch(1).map(preprocess):\n",
    "    xnew = raw_x_train.extend(x[0].to_list())\n",
    "    ynew = raw_y_train.extend(x[1].to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total unique words in the input: 211926\n",
      "Length of longest sentence in input: 70\n",
      "\n",
      "Total unique words in the output: 83634\n",
      "Length of longest sentence in the output: 32\n"
     ]
    }
   ],
   "source": [
    "max_source_len=75\n",
    "max_target_len=10\n",
    "\n",
    "# Tokenize article content\n",
    "input_tokenizer = Tokenizer()\n",
    "input_tokenizer.fit_on_texts(list(raw_x_train))\n",
    "input_integer_seq = input_tokenizer.texts_to_sequences(raw_x_train)\n",
    "    \n",
    "word2idx_inputs = input_tokenizer.word_index\n",
    "print(\"Total unique words in the input: {}\".format(len(word2idx_inputs)))\n",
    "\n",
    "max_input_len = max(len(content) for content in input_integer_seq)\n",
    "print(\"Length of longest sentence in input: {}\\n\".format(max_input_len))\n",
    "      \n",
    "# Tokenize article title\n",
    "output_tokenizer = Tokenizer(filters='')\n",
    "output_tokenizer.fit_on_texts(list(raw_y_train))\n",
    "output_integer_seq = output_tokenizer.texts_to_sequences(raw_y_train)\n",
    "\n",
    "word2idx_outputs = output_tokenizer.word_index\n",
    "print(\"Total unique words in the output: {}\".format(len(word2idx_outputs)))\n",
    "\n",
    "num_words_output = len(word2idx_outputs) + 1\n",
    "max_out_len = max(len(sen) for sen in output_integer_seq)\n",
    "print(\"Length of longest sentence in the output: {}\".format(max_out_len))\n",
    "\n",
    "encoder_input_sequences = pad_sequences(input_integer_seq, maxlen=max_source_len, padding='post')\n",
    "decoder_input_sequences = pad_sequences(output_integer_seq, maxlen=max_target_len, padding='post')\n",
    "\n",
    "x_vocab = len(input_tokenizer.word_index) + 1\n",
    "y_vocab = len(output_tokenizer.word_index) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Attention Layer pulled from here: https://github.com/thushv89/attention_keras/blob/master/src/layers/attention.py\n",
    "class AttentionLayer(Layer):\n",
    "    \"\"\"\n",
    "    This class implements Bahdanau attention (https://arxiv.org/pdf/1409.0473.pdf).\n",
    "    There are three sets of weights introduced W_a, U_a, and V_a\n",
    "     \"\"\"\n",
    "\n",
    "    def __init__(self, **kwargs):\n",
    "        super(AttentionLayer, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        assert isinstance(input_shape, list)\n",
    "        # Create a trainable weight variable for this layer.\n",
    "\n",
    "        self.W_a = self.add_weight(name='W_a',\n",
    "                                   shape=tf.TensorShape((input_shape[0][2], input_shape[0][2])),\n",
    "                                   initializer='uniform',\n",
    "                                   trainable=True)\n",
    "        self.U_a = self.add_weight(name='U_a',\n",
    "                                   shape=tf.TensorShape((input_shape[1][2], input_shape[0][2])),\n",
    "                                   initializer='uniform',\n",
    "                                   trainable=True)\n",
    "        self.V_a = self.add_weight(name='V_a',\n",
    "                                   shape=tf.TensorShape((input_shape[0][2], 1)),\n",
    "                                   initializer='uniform',\n",
    "                                   trainable=True)\n",
    "\n",
    "        super(AttentionLayer, self).build(input_shape)  # Be sure to call this at the end\n",
    "\n",
    "    def call(self, inputs, verbose=False):\n",
    "        \"\"\"\n",
    "        inputs: [encoder_output_sequence, decoder_output_sequence]\n",
    "        \"\"\"\n",
    "        assert type(inputs) == list\n",
    "        encoder_out_seq, decoder_out_seq = inputs\n",
    "        if verbose:\n",
    "            print('encoder_out_seq>', encoder_out_seq.shape)\n",
    "            print('decoder_out_seq>', decoder_out_seq.shape)\n",
    "\n",
    "        def energy_step(inputs, states):\n",
    "            \"\"\" Step function for computing energy for a single decoder state\n",
    "            inputs: (batchsize * 1 * de_in_dim)\n",
    "            states: (batchsize * 1 * de_latent_dim)\n",
    "            \"\"\"\n",
    "\n",
    "            assert_msg = \"States must be an iterable. Got {} of type {}\".format(states, type(states))\n",
    "            assert isinstance(states, list) or isinstance(states, tuple), assert_msg\n",
    "\n",
    "            \"\"\" Some parameters required for shaping tensors\"\"\"\n",
    "            en_seq_len, en_hidden = encoder_out_seq.shape[1], encoder_out_seq.shape[2]\n",
    "            de_hidden = inputs.shape[-1]\n",
    "\n",
    "            \"\"\" Computing S.Wa where S=[s0, s1, ..., si]\"\"\"\n",
    "            # <= batch size * en_seq_len * latent_dim\n",
    "            W_a_dot_s = K.dot(encoder_out_seq, self.W_a)\n",
    "\n",
    "            \"\"\" Computing hj.Ua \"\"\"\n",
    "            U_a_dot_h = K.expand_dims(K.dot(inputs, self.U_a), 1)  # <= batch_size, 1, latent_dim\n",
    "            if verbose:\n",
    "                print('Ua.h>', U_a_dot_h.shape)\n",
    "\n",
    "            \"\"\" tanh(S.Wa + hj.Ua) \"\"\"\n",
    "            # <= batch_size*en_seq_len, latent_dim\n",
    "            Ws_plus_Uh = K.tanh(W_a_dot_s + U_a_dot_h)\n",
    "            if verbose:\n",
    "                print('Ws+Uh>', Ws_plus_Uh.shape)\n",
    "\n",
    "            \"\"\" softmax(va.tanh(S.Wa + hj.Ua)) \"\"\"\n",
    "            # <= batch_size, en_seq_len\n",
    "            e_i = K.squeeze(K.dot(Ws_plus_Uh, self.V_a), axis=-1)\n",
    "            # <= batch_size, en_seq_len\n",
    "            e_i = K.softmax(e_i)\n",
    "\n",
    "            if verbose:\n",
    "                print('ei>', e_i.shape)\n",
    "\n",
    "            return e_i, [e_i]\n",
    "\n",
    "        def context_step(inputs, states):\n",
    "            \"\"\" Step function for computing ci using ei \"\"\"\n",
    "\n",
    "            assert_msg = \"States must be an iterable. Got {} of type {}\".format(states, type(states))\n",
    "            assert isinstance(states, list) or isinstance(states, tuple), assert_msg\n",
    "\n",
    "            # <= batch_size, hidden_size\n",
    "            c_i = K.sum(encoder_out_seq * K.expand_dims(inputs, -1), axis=1)\n",
    "            if verbose:\n",
    "                print('ci>', c_i.shape)\n",
    "            return c_i, [c_i]\n",
    "\n",
    "        fake_state_c = K.sum(encoder_out_seq, axis=1)\n",
    "        fake_state_e = K.sum(encoder_out_seq, axis=2)  # <= (batch_size, enc_seq_len, latent_dim\n",
    "\n",
    "        \"\"\" Computing energy outputs \"\"\"\n",
    "        # e_outputs => (batch_size, de_seq_len, en_seq_len)\n",
    "        last_out, e_outputs, _ = K.rnn(\n",
    "            energy_step, decoder_out_seq, [fake_state_e],\n",
    "        )\n",
    "\n",
    "        \"\"\" Computing context vectors \"\"\"\n",
    "        last_out, c_outputs, _ = K.rnn(\n",
    "            context_step, e_outputs, [fake_state_c],\n",
    "        )\n",
    "\n",
    "        return c_outputs, e_outputs\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        \"\"\" Outputs produced by the layer \"\"\"\n",
    "        return [\n",
    "            tf.TensorShape((input_shape[1][0], input_shape[1][1], input_shape[1][2])),\n",
    "            tf.TensorShape((input_shape[1][0], input_shape[1][1], input_shape[0][1]))\n",
    "        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_2 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_2 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_3 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_3 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n"
     ]
    }
   ],
   "source": [
    "# Load model\n",
    "model = keras.models.load_model('wikipediaModel.h5', custom_objects={'AttentionLayer': AttentionLayer})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_2 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_2 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_3 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_3 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 75)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, 75, 100)      21192700    input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm (LSTM)                     [(None, 75, 75), (No 52800       embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   [(None, 75, 75), (No 45300       lstm[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, None, 100)    8363500     input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_2 (LSTM)                   [(None, 75, 75), (No 45300       lstm_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "lstm_3 (LSTM)                   [(None, None, 75), ( 52800       embedding_1[0][0]                \n",
      "                                                                 lstm_2[0][1]                     \n",
      "                                                                 lstm_2[0][2]                     \n",
      "__________________________________________________________________________________________________\n",
      "attention_layer (AttentionLayer ((None, None, 75), ( 11325       lstm_2[0][0]                     \n",
      "                                                                 lstm_3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "concat_layer (Concatenate)      (None, None, 150)    0           lstm_3[0][0]                     \n",
      "                                                                 attention_layer[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed (TimeDistribut (None, None, 83635)  12628885    concat_layer[0][0]               \n",
      "==================================================================================================\n",
      "Total params: 42,392,610\n",
      "Trainable params: 42,392,610\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Build Model - use three stacked LSTM with attention layer\n",
    "latent_dim = max_source_len\n",
    "embedding_dim = 100\n",
    "\n",
    "# Encoder\n",
    "encoder_inputs = keras.layers.Input(shape=(max_source_len))\n",
    "\n",
    "# Embedding Layer\n",
    "enc_emb =  Embedding(x_vocab,embedding_dim,trainable=True)(encoder_inputs)\n",
    "\n",
    "#encoder lstm 1\n",
    "encoder_lstm1 = LSTM(latent_dim,return_sequences=True,return_state=True,dropout=0.3,recurrent_dropout=0.3)\n",
    "encoder_output1, state_h1, state_c1 = encoder_lstm1(enc_emb)\n",
    "\n",
    "#encoder lstm 2\n",
    "encoder_lstm2 = LSTM(latent_dim,return_sequences=True,return_state=True,dropout=0.3,recurrent_dropout=0.3)\n",
    "encoder_output2, state_h2, state_c2 = encoder_lstm2(encoder_output1)\n",
    "\n",
    "#encoder lstm 3\n",
    "encoder_lstm3=LSTM(latent_dim, return_state=True, return_sequences=True,dropout=0.3,recurrent_dropout=0.3)\n",
    "encoder_outputs, state_h, state_c= encoder_lstm3(encoder_output2)\n",
    "\n",
    "# Set up the decoder, using `encoder_states` as initial state.\n",
    "decoder_inputs = Input(shape=(None,))\n",
    "\n",
    "#embedding layer\n",
    "dec_emb_layer = Embedding(y_vocab, embedding_dim,trainable=True)\n",
    "dec_emb = dec_emb_layer(decoder_inputs)\n",
    "\n",
    "decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True,dropout=0.2,recurrent_dropout=0.2)\n",
    "decoder_outputs,decoder_fwd_state, decoder_back_state = decoder_lstm(dec_emb,initial_state=[state_h, state_c])\n",
    "\n",
    "# Attention layer\n",
    "attn_layer = AttentionLayer(name='attention_layer')\n",
    "attn_out, attn_states = attn_layer([encoder_outputs, decoder_outputs])\n",
    "\n",
    "# Concat attention input and decoder LSTM output\n",
    "decoder_concat_input = Concatenate(axis=-1, name='concat_layer')([decoder_outputs, attn_out])\n",
    "\n",
    "# Dense layer\n",
    "decoder_dense =  TimeDistributed(Dense(y_vocab, activation='softmax'))\n",
    "decoder_outputs = decoder_dense(decoder_concat_input)\n",
    "\n",
    "# Define the model \n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode the input sequence to get the feature vector\n",
    "encoder_model = Model(inputs=encoder_inputs,outputs=[encoder_outputs, state_h, state_c])\n",
    "\n",
    "# Decoder setup\n",
    "# Below tensors will hold the states of the previous time step\n",
    "decoder_state_input_h = Input(shape=(latent_dim,))\n",
    "decoder_state_input_c = Input(shape=(latent_dim,))\n",
    "decoder_hidden_state_input = Input(shape=(max_source_len,latent_dim))\n",
    "\n",
    "# Get the embeddings of the decoder sequence\n",
    "dec_emb2= dec_emb_layer(decoder_inputs) \n",
    "# To predict the next word in the sequence, set the initial states to the states from the previous time step\n",
    "decoder_outputs2, state_h2, state_c2 = decoder_lstm(dec_emb2, initial_state=[decoder_state_input_h, decoder_state_input_c])\n",
    "\n",
    "# Attention inference\n",
    "attn_out_inf, attn_states_inf = attn_layer([decoder_hidden_state_input, decoder_outputs2])\n",
    "decoder_inf_concat = Concatenate(axis=-1, name='concat')([decoder_outputs2, attn_out_inf])\n",
    "\n",
    "# A dense softmax layer to generate prob dist. over the target vocabulary\n",
    "decoder_outputs2 = decoder_dense(decoder_inf_concat) \n",
    "\n",
    "# Final decoder model\n",
    "decoder_model = Model(\n",
    "    [decoder_inputs] + [decoder_hidden_state_input,decoder_state_input_h, decoder_state_input_c],\n",
    "    [decoder_outputs2] + [state_h2, state_c2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the dictionary to convert the index to word for target and source vocabulary:\n",
    "reverse_target_word_index=output_tokenizer.index_word\n",
    "reverse_source_word_index=input_tokenizer.index_word\n",
    "target_word_index=output_tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function below is the inference process\n",
    "def decode_sequence(input_seq):\n",
    "    # Encode the input as state vectors.\n",
    "    e_out, e_h, e_c = encoder_model.predict(input_seq)\n",
    "    \n",
    "    # Generate empty target sequence of length 1.\n",
    "    target_seq = np.zeros((1,1))\n",
    "    \n",
    "    # Populate the first word of target sequence with the start word.\n",
    "    target_seq[0, 0] = target_word_index[b'<start>']\n",
    "\n",
    "    stop_condition = False\n",
    "    decoded_sentence = ''\n",
    "    while not stop_condition:\n",
    "      \n",
    "        output_tokens, h, c = decoder_model.predict([target_seq] + [e_out, e_h, e_c])\n",
    "\n",
    "        # Sample a token\n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "        sampled_token = reverse_target_word_index[sampled_token_index]\n",
    "        \n",
    "        if(sampled_token!=b'<end>'):\n",
    "            decoded_sentence += ' '+ str(sampled_token)\n",
    "\n",
    "        # Exit condition: either hit max length or find stop word.\n",
    "        if (sampled_token == b'<end>'  or len(decoded_sentence.split()) >= (max_target_len-1)):\n",
    "            stop_condition = True\n",
    "\n",
    "        # Update the target sequence (of length 1).\n",
    "        target_seq = np.zeros((1,1))\n",
    "        target_seq[0, 0] = sampled_token_index\n",
    "\n",
    "        # Update internal states\n",
    "        e_h, e_c = h, c\n",
    "\n",
    "    return decoded_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source Sentence: b'joseph' b'harold' b'greenberg' b'may' b'may' b'was' b'an' b'american' b'linguist' b'known' b'mainly' b'for' b'his' b'work' b'concerning' b'linguistic' b'typology' b'and' b'the' b'genetic' b'classification' b'of' b'languages' b'life' b'early' b'life' b'and' b'education' b'main' b'source' b'croft' b'joseph' b'greenberg' b'was' b'born' b'on' b'may' b'to' b'jewish' b'paren' \n",
      "Original Target: b'joseph' b'greenberg' \n",
      "Predicted Target:  b'swim' b'metefara' b'jastremski' b'pf' b'given' b'hendrawan' b'django' b'embleton' b'drama'\n",
      "\n",
      "\n",
      "Source Sentence: b'pauline' b'donalda' b'march' b'october' b'was' b'a' b'canadian' b'operatic' b'soprano' b'early' b'life' b'and' b'education' b'donalda' b'was' b'born' b'pauline' b'lightstone' b'in' b'montreal' b'quebec' b'the' b'daughter' b'of' b'jewish' b'parents' b'who' b'changed' b'their' b'surname' b'from' b'lichtenstein' b'to' b'lightstone' b'after' b'immigrating' b'from' b'russia' b'and' b'poland' \n",
      "Original Target: b'pauline' b'donalda' \n",
      "Predicted Target:  b'lordship' b'kalakala' b'papirius' b'suurij' b'wolfhart' b'clanwilliam' b'phenomena' b'teauguay' b'dargai'\n",
      "\n",
      "\n",
      "Source Sentence: b'this' b'is' b'a' b'list' b'of' b'german' b'football' b'transfers' b'in' b'the' b'summer' b'transfer' b'window' b'by' b'club' b'only' b'transfers' b'of' b'the' b'bundesliga' b'and' b'bundesliga' b'are' b'included' b'bundesliga' b'note' b'flags' b'indicate' b'national' b'team' b'as' b'has' b'been' b'defined' b'under' b'fifa' b'eligibility' b'rules' b'players' b'may' b'hold' b'more' b'than' b'one' b'non' b'fifa' b'national' \n",
      "Original Target: b'list' b'of' b'german' b'football' b'transfers' b'summer' \n",
      "Predicted Target:  b'jaitwara' b'shed' b'commissionings' b'sielce' b'mcnairn' b'mcnairn' b'anadolu' b'rodrigo' b'lisabeth'\n",
      "\n",
      "\n",
      "Source Sentence: b'lester' b'hudson' b'iii' b'born' b'august' b'is' b'an' b'american' b'professional' b'basketball' b'player' b'who' b'currently' b'plays' b'for' b'the' b'liaoning' b'flying' b'leopards' b'of' b'the' b'chinese' b'basketball' b'association' b'cba' b'in' b'the' b'season' b'hudson' b'recorded' b'the' b'only' b'quadruple' b'double' b'in' b'ncaa' b'division' b'i' b\"men's\" b'basketball' b'history' b'at' b't' \n",
      "Original Target: b'lester' b'hudson' \n",
      "Predicted Target:  b'madhuve' b'uterine' b'szepietowo' b'vessel' b'mathews' b'popenoe' b'yermalovich' b'daharan' b'anglada'\n",
      "\n",
      "\n",
      "Source Sentence: b'monique' b'ganderton' b'born' b'august' b'is' b'a' b'canadian' b'stunt' b'woman' b'and' b'actress' b'who' b'works' b'in' b'television' b'and' b'film' b'ganderton' b'was' b'born' b'in' b'edmonton' b'alberta' b'she' b'started' b'out' b'in' b'modeling' b'before' b'moving' b'to' b'stunt' b'work' b'she' b'has' b'doubled' b'tricia' b'helfer' b'rachel' b'nichols' b'leelee' b'sobieski' b'bridget' b'moynahan' b'daryl' \n",
      "Original Target: b'monique' b'ganderton' \n",
      "Predicted Target:  b'swim' b'metefara' b'vincenc' b'bruning' b'sweetheart' b'tade' b'uterine' b'nursing' b'ezimilo'\n",
      "\n",
      "\n",
      "Source Sentence: b'this' b'is' b'a' b'list' b'of' b'women' b'artists' b'who' b'were' b'born' b'in' b'latvia' b'or' b'whose' b'artworks' b'are' b'closely' b'associated' b'with' b'that' b'country' b'b' b'aleksandra' b'belcova' b'painter' b'biruta' b'baumane' b'born' b'painter' b'd' b'lilija' b'dinere' b'born' b'painter' b'illustrator' b'k' b'ingr' b'da' b'kadaka' b'born' b'book' b'designer' b'illus' \n",
      "Original Target: b'list' b'of' b'latvian' b'women' b'artists' \n",
      "Predicted Target:  b'lordship' b'erenberg' b'upton' b'suurij' b'sheltered' b'movement' b'boa' b'boa' b'saracini'\n",
      "\n",
      "\n",
      "Source Sentence: b'the' b'white' b'bikini' b'of' b'ursula' b'andress' b'also' b'known' b'as' b'the' b'dr' b'no' b'bikini' b'was' b'a' b'white' b'bikini' b'worn' b'by' b'ursula' b'andress' b'as' b'honey' b'ryder' b'in' b'the' b'james' b'bond' b'film' b'dr' b'no' b'it' b'is' b'cited' b'as' b'the' b'most' b'famous' b'bikini' b'of' b'all' b'time' b'and' b'an' b'iconic' b'moment' b'in' b'cinematic' b'and' b'fashion' b'history' b\"andress's\" b'white' b'bikini' b'is' b'regar' \n",
      "Original Target: b'white' b'bikini' b'of' b'ursula' b'andress' \n",
      "Predicted Target:  b'seefood' b'vodoun' b'internata' b'nematode' b'ghazzi' b'vadhanapanich' b'georgiacarry' b'aguape' b'oshri'\n",
      "\n",
      "\n",
      "Source Sentence: b'cellana' b'radians' b'common' b'name' b'the' b'radiate' b'limpet' b'is' b'a' b'species' b'of' b'true' b'limpet' b'a' b'marine' b'gastropod' b'mollusc' b'in' b'the' b'family' b'nacellidae' b'which' b'is' b'one' b'of' b'the' b'true' b'limpet' b'families' b'description' b'the' b'foot' b'and' b'the' b'head' b'are' b'lightly' b'colored' b'whereas' b'cellana' b'flava' b'has' b'darker' b'colored' b'soft' b'tissues' b'the' b'shell' b'exhibit' \n",
      "Original Target: b'cellana' b'radians' \n",
      "Predicted Target:  b'lordship' b'airlift' b'clipsal' b'stoichiometric' b'patrykozy' b'villebourg' b'parkin' b'competition' b'morong'\n",
      "\n",
      "\n",
      "Source Sentence: b'onthophagus' b'adelaidae' b'is' b'a' b'species' b'of' b'beetle' b'discovered' b'by' b'frederick' b'william' b'hope' b'in' b'no' b'sub' b'species' b'are' b'listed' b'at' b'catalogue' b'of' b'life' b'references' b'category' b'scarabaeinae' \n",
      "Original Target: b'onthophagus' b'adelaidae' \n",
      "Predicted Target:  b'madhuve' b'szepietowo' b'fincke' b'aibou' b'findern' b'fincke' b'findern' b'fincke' b'marienhof'\n",
      "\n",
      "\n",
      "Source Sentence: b'neal' b'alexander' b'scott' b'mackey' b'born' b'february' b'is' b'an' b'english' b'cricketer' b'mackey' b'is' b'a' b'right' b'handed' b'batsman' b'who' b'bowls' b'right' b'arm' b'medium' b'fast' b'he' b'was' b'born' b'in' b'leicester' b'leicestershire' b'mackey' b'represented' b'the' b'leicestershire' b'cricket' b'board' b'in' b'a' b'single' b'list' b'a' b'match' b'against' b'the' b'kent' b'cricket' b'board' b'in' b't' \n",
      "Original Target: b'neal' b'mackey' \n",
      "Predicted Target:  b'swim' b'metefara' b'vincenc' b'bruning' b'sweetheart' b'promised' b'retford' b'retford' b'goraj'\n",
      "\n",
      "\n",
      "Source Sentence: b'jna' b'wireless' b'association' b'is' b'an' b'amateur' b'radio' b'organisation' b'based' b'in' b'mumbai' b'formerly' b'bombay' b'in' b'india' b'jna' b'was' b'founded' b'in' b'in' b'memory' b'of' b'late' b'avid' b'amateur' b'radio' b'operator' b'jamshed' b'n' b'anklesaria' b'callsign' b'vu' b'jna' b'who' b'died' b'in' b'the' b'organisation' b'currently' b'headed' b'by' b'sudhir' b'shah' b'vu' b'svs' b'conducts' \n",
      "Original Target: b'jna' b'wireless' b'association' \n",
      "Predicted Target:  b'woodchester' b'redmanizers' b'exemption' b'exemption' b'exemption' b'exemption' b'exemption' b'exemption' b'exemption'\n",
      "\n",
      "\n",
      "Source Sentence: b'the' b'arabic' b'numeral' b'series' b'sometimes' b'referred' b'to' b'as' b'the' b'arabics' b'is' b'a' b'series' b'of' b'short' b'mm' b'films' b'completed' b'by' b'the' b'american' b'experimental' b'filmmaker' b'stan' b'brakhage' b'in' b'and' b'the' b'arabic' b'numeral' b'series' b'gets' b'its' b'name' b'from' b'the' b'fact' b'that' b'none' b'of' b'the' b'films' b'included' b'in' b'it' b'have' b'titles' b'instead' b'openi' \n",
      "Original Target: b'arabic' b'numeral' b'series' \n",
      "Predicted Target:  b'rkan' b'lordship' b'papirius' b'suurij' b'sari' b'triangularis' b'baava' b'vid' b'flavin'\n",
      "\n",
      "\n",
      "Source Sentence: b'no' b'stranger' b'to' b'danger' b'is' b'the' b'second' b'album' b'by' b'the' b'payolas' b'released' b'in' b'it' b'contains' b'the' b'hit' b'eyes' b'of' b'a' b'stranger' b'the' b'album' b'is' b'only' b'available' b'on' b'vinyl' b'and' b'cassette' b'it' b'has' b'not' b'been' b'released' b'on' b'cd' b'or' b'as' b'a' b'commercial' b'digital' b'download' b'although' b'some' b'tracks' b'notably' b'romance' b'and' b'eyes' b'of' b'a' b'strang' \n",
      "Original Target: b'no' b'stranger' b'to' b'danger' b'payolas' b'album' \n",
      "Predicted Target:  b'biltauere' b'torch' b'coaster' b'coaster' b'semprong' b'basicola' b'spradlin' b'quisling' b'teela'\n",
      "\n",
      "\n",
      "Source Sentence: b'the' b'bienwald' b'is' b'a' b'large' b'forested' b'area' b'in' b'the' b'southern' b'pfalz' b'region' b'of' b'germany' b'near' b'the' b'towns' b'of' b'kandel' b'and' b'w' b'rth' b'am' b'rhein' b'the' b'western' b'edge' b'defines' b'the' b'eastern' b'extent' b'of' b'the' b'wissembourg' b'gap' b'a' b'corridor' b'of' b'open' b'terrain' b'between' b'the' b'bienwald' b'and' b'the' b'hills' b'of' b'the' b'palatine' b'forest' b'in' b'the' b'northwest' b'th' \n",
      "Original Target: b'bienwald' \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Target:  b'lordship' b'airlift' b'clipsal' b'stoichiometric' b'patrykozy' b'villebourg' b'parkin' b'competition' b'morong'\n",
      "\n",
      "\n",
      "Source Sentence: b'is' b'a' b'japanese' b'anime' b'television' b'series' b'broadcast' b'from' b'february' b'to' b'march' b'comprising' b'episodes' b'it' b'is' b'the' b'sixth' b'entry' b'to' b'the' b'time' b'bokan' b'series' b'by' b'tatsunoko' b'productions' b'and' b'the' b'first' b'series' b'to' b'feature' b'a' b'super' b'robot' b'as' b'the' b'main' b'hero' b'the' b'series' b'succeeded' b'yattodetaman' b'and' b'preceded' b'ita' \n",
      "Original Target: b'gyakuten' b'ippatsuman' \n",
      "Predicted Target:  b'infernal' b'desmosome' b'denji' b'dulcinea' b'juraj' b'rejects' b'goodwillie' b'superpower' b'brandshaug'\n",
      "\n",
      "\n",
      "Source Sentence: b'breakout' b'is' b'a' b'single' b'from' b'british' b'act' b'swing' b'out' b\"sister's\" b'debut' b'album' b\"it's\" b'better' b'to' b'travel' b'the' b'single' b'reached' b'the' b'number' b'four' b'position' b'in' b'the' b'uk' b'in' b'the' b'autumn' b'of' b'and' b'rose' b'to' b'number' b'six' b'on' b'the' b'billboard' b'hot' b'in' b'the' b'us' b'and' b'number' b'one' b'on' b'the' b'adult' b'contemporary' b'in' b'the' b'us' b'in' b'the' b'song' b'a' \n",
      "Original Target: b'breakout' b'swing' b'out' b'sister' b'song' \n",
      "Predicted Target:  b'biltauere' b'laminated' b'bachillerato' b'baeonoma' b'alfund' b'przysieka' b'mandler' b'solace' b'branco'\n",
      "\n",
      "\n",
      "Source Sentence: b'kellys' b'cellars' b'is' b'a' b'pub' b'in' b'belfast' b'northern' b'ireland' b'situated' b'at' b'bank' b'street' b'in' b'the' b'city' b'centre' b'built' b'in' b'march' b'it' b'is' b'one' b'of' b'the' b'oldest' b'pubs' b'of' b'belfast' b'it' b'sits' b'in' b'what' b'used' b'to' b'be' b'an' b'alley' b'way' b'off' b'royal' b'avenue' b'but' b'a' b'few' b'buildings' b'were' b'knocked' b'down' b'and' b'now' b'kellys' b'sits' b'in' b'a' b'square' b'besi' \n",
      "Original Target: b\"kelly's\" b'cellars' \n",
      "Predicted Target:  b'rkan' b'segura' b'turtle' b'momble' b'equatorial' b'ringera' b'paulista' b'friedlander' b'wares'\n",
      "\n",
      "\n",
      "Source Sentence: b'troy' b'meadows' b'is' b'a' b'nature' b'preserve' b'in' b'parsippany' b'morris' b'county' b'new' b'jersey' b'along' b'with' b'the' b'great' b'swamp' b'it' b'is' b'one' b'of' b'the' b'remnants' b'of' b'glacial' b'lake' b'passaic' b'it' b'was' b'designated' b'a' b'national' b'natural' b'landmark' b'in' b'it' b'is' b'the' b'largest' b'freshwater' b'marsh' b'in' b'new' b'jersey' b'the' b'whippany' b'river' b'goes' b'through' b'the' b's' \n",
      "Original Target: b'troy' b'meadows' \n",
      "Predicted Target:  b'lordship' b'airlift' b'clipsal' b'stoichiometric' b'patrykozy' b'villebourg' b'askildsen' b'sophiarum' b'sarbanes'\n",
      "\n",
      "\n",
      "Source Sentence: b'the' b'generalized' b'vector' b'space' b'model' b'is' b'a' b'generalization' b'of' b'the' b'vector' b'space' b'model' b'used' b'in' b'information' b'retrieval' b'wong' b'et' b'al' b'presented' b'an' b'analysis' b'of' b'the' b'problems' b'that' b'the' b'pairwise' b'orthogonality' b'assumption' b'of' b'the' b'vector' b'space' b'model' b'vsm' b'creates' b'from' b'here' b'they' b'extended' b'the' b'vsm' b'to' b'the' b'generalized' b'vec' \n",
      "Original Target: b'generalized' b'vector' b'space' b'model' \n",
      "Predicted Target:  b'madhuve' b'isambard' b'warum' b'kittel' b'rehak' b'gunzelin' b'conjectures' b'hajn' b'canavan'\n",
      "\n",
      "\n",
      "Source Sentence: b'marantu' b'also' b'romanized' b'as' b'm' b'r' b'nt' b'is' b'a' b'village' b'in' b'cham' b'chamal' b'rural' b'district' b'bisotun' b'district' b'harsin' b'county' b'kermanshah' b'province' b'iran' b'at' b'the' b'census' b'its' b'population' b'was' b'in' b'families' b'references' b'category' b'populated' b'places' b'in' b'harsin' b'county' \n",
      "Original Target: b'marantu' \n",
      "Predicted Target:  b'madhuve' b'uterine' b'szepietowo' b'vessel' b'mathews' b'popenoe' b'popenoe' b'mohlakeng' b'sunrise'\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Number of articles to generate a title\n",
    "num_articles  = 20\n",
    "\n",
    "def seq_to_target(input_seq):\n",
    "    newString=''\n",
    "    for i in input_seq:\n",
    "        if((i!=0 and i!=target_word_index[b'<start>']) and i!=target_word_index[b'<end>']):\n",
    "            newString=newString+str(reverse_target_word_index[i])+' '\n",
    "    return newString\n",
    "\n",
    "def seq_to_source(input_seq):\n",
    "    newString=''\n",
    "    for i in input_seq:\n",
    "        if(i!=0):\n",
    "            newString=newString+str(reverse_source_word_index[i])+' '\n",
    "    return newString\n",
    "\n",
    "for i in range(0,num_articles):\n",
    "    print(\"Source Sentence:\",seq_to_source(encoder_input_sequences[i]))\n",
    "    print(\"Original Target:\",seq_to_target(decoder_input_sequences[i]))\n",
    "    print(\"Predicted Target:\",decode_sequence(encoder_input_sequences[i].reshape(1,max_source_len)))\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
